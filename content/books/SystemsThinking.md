---
title: "Thinking in Systems: A Primer"
author: Donnella Meadows
---

* If you understand the _dynamics_ of stock and flows, their behaviour through time you understand a good deal about the
  behaviour of the complex system.
* Stock has inertia in most systems. For instance, you can't just drain the tap on all the factories or coal powered
  plants in an economy. There are restrictions on that flow.
* > Changes in stocks set the pace of the dynamics of systems. Industrialization cannot proceed faster than the rate at
  which factories and machines can be constructed and the rate at which human beings can be educated to run and maintain
  them. Forests can’t grow overnight. Once contaminants have accumulated in groundwater, they can be washed out only at
  the rate of groundwater turnover, which may take decades or even centuries.
* This allows inflows and outflows to be decoupled.
* > Systems thinkers see the world as a collection of stocks along with the mechanisms for regulating the levels in the
  stocks by manipulating flows.
* In this way seeing the world as a collection of feedback loops, where inputs and output flows are altered based on
  some stock level that is deemed the goal level.
* These are known as balancing feedback loops.
* Another kind of loop is a reinforcing loop
* > Reinforcing loops are found wherever a system element has the ability to reproduce itself or to grow as a constant
  fraction of itself.
* There's a way of thinking that Meadows is trying to get at where instead of just seeing how A might cause B, look at
  how B might then influence A.
  > Reinforcing loops are found wherever a system element has the ability to reproduce itself or to grow as a constant
  fraction of itself.

## A stock with one balancing and one reinforcing loop

* The reinforcing loop of growing through the birth rate.
* The balancing loop of death rate.
* If one was let dominate, the stock (number of living people) would increase infinitely or go towards zero. Increasing
  at a faster rate obviously.
* These rates, of fertility and mortality shift through time, the complexity of behaviour of a lot of systems is the
  shifting behaviour of their feedback loops causing one to dominate the other.
* If we wanted to look and population growth and we have this model of the system, to predict 'what if' scenarios we
  ask:
    * What are the birth and death rate likely to do? (what are the driving factors of the stock going to do).
    * If they change that way, what happens to the stock (population)?
    * What affects birth rate? What affects death rate?
* Dynamic systems are designed to _explore_ what would happen, not predict what will happen.

* Delays in system can manifest as oscillations in the stock over the long run.
* This is because delays can cause overshooting of flows into the system.

## Constraints to systems

 > Whenever we see a growing entity, whether it be a population, a corporation, a bank account, a rumor, an epidemic,
  > or sales of a new product, we look for the reinforcing loops that are driving it and for the balancing loops that
  > ultimately will constrain it. We know those balancing loops are there, even if they are not yet dominating the
  > system’s behavior, because no real physical system can grow forever.

## Self-Organization

> Systems often have the property of self-organization—the ability to structure themselves, to create new structure, to
learn, diversify, and complexify. Even complex forms of self-organization may arise from relatively simple organizing
rules—or may not.

* Somewhat emergent form the notion of _resilience_ of a system is that of self-organization.
* Meta-resilience is equated to Antifragility from Taleb [^1]. Next time the stimulus happens again, the system is more
  resilient to it. This is similar to vaccines, where you poke the system to build up stronger defenses for a bigger
  poke of the same type.
* Systems need to be managed, not only for productivity or stability but for resilience.
* > This capacity of a system to make its own structure more complex is called self-organization.
* This, like resilience is often sacrificed for short term productivity or stability gains. Like sticking with large
  monopoly companies due to their known, deterministic behaviour or not promoting creativity in the education systems as
  it will introduce unknown quantities.
* A few simple rules, like the basic instruction set of a computer can lead to a vast range of self-organizing systems.
  An example would be the instructions in DNA as well.
* Meadows uses an example here of the church, that on the precept of
  > “God created the universe with the earth at its center, the land with the castle at its center, and humanity with
  the Church at its center”—the organizing principle for the elaborate social and physical structures of Europe in the
  Middle Ages.
  you get this vast array of behaviour. It's all the one system, but it is emergent from those simple instructions due
  to its self-organizing capability. **The initial statement allows for enough variation in interpretation to allow a wide set of possible outcomes.**

## Hierarchies

* This interlude at the end of Chapter 1 of part 2 echoes the electrical engineering notion of sub-systems. Something
  I'm seeing in computer architecture too. Abstraction over implementation:
  > Hierarchies are brilliant systems inventions, not only because they give a system stability and resilience, but also
  because they reduce the amount of information that any part of the system has to keep track of. - Herbert Simon
* These subsystem can be very tightly interconnected, to the point where they are basically independent. It's important
  to keep in mind the overarching system in which they're operating.
* Hierarchies form to most efficiently perform the subsystem task. Sometimes this behaviour, or function that the
  subsystem is performing is not aligned with the wider systems goal in which case the system is suboptimal.
* Ultimately there must be
  > enough central control to achieve coordination toward the large system goal, and enough autonomy to keep all
  subsystems flourishing, functioning, and self-organizing.

# Chapter 4

Three truths:
* Everything we know about the world is a model.
* These model usually have strong congruences with the world.
* They fall short of representing the world fully.

* Systems thinking goes back and forth between a systems structure (like diagrams) and the system behaviour (time series
  graphs, events through time).
* The first thing a system thinker does when analysing something is look for time graphs, data on the history of the
  system. These time graphs are the behaviour of the system. Long term behaviour provides clues as to the structure of
  the system, key to understanding not just what is happening, but _why_.
* The notion of non linear relationships. Soil erosion is used as an example where you expect some increase in input to
  improve crop yields through time, you hit a certain depth where this is no longer the case.
    * This is similar to how Insull saw the development of electricity generation technology, in 20 years after a two
      percent efficient plant in the early 1900's you had a 12 percent efficient one, then another decade, 20 percent. The
      Carnot efficiency loomed large but was ignored due to that tendency to disregard non linear relationships.

[^1]: https://www.youtube.com/watch?v=2qOc_0DMqaA Around the two min mark.
